---
title: "Practical Machine Learning Project"
author: "Al Anderson"
date: "August 5, 2015"
output: html_document
---
``` {r echo = FALSE, include = FALSE}
library(dplyr)
library(caret)
```
# Raw Data Evaluation and Cleanup
## Introduction

This data is from http://groupware.les.inf.puc-rio.br/har. It is Weight Lifting Exercise data. It consists of a number of variables generated by accelerometers attached to people lifting weights. The individuals lifted a barbell in five different manners. The manner of lifting is in the classe field. This is the field of interest to see if our model can predict this value from the data that the accelerometers generated.

## Data Cleanup
The data was reviewed and only the columns with complete data were selected. The dplyr function ```filter(trData, new_window == "no")``` was used to remove the rows that corresponded to the metadata rows inserted by the authors of the original experiment. Then the command
```
trainData[,-c(1,2,6,7,12:36,50:59,69:83,87:101,103:112,125:139,141:150)]
``` 
was used to select the desired columns. Columns removed included those associated with the metadata for the new_window and num_window variables.  This results in a wide tidy dataset.

The code below is the actual code used to load the data and clean it up.

```{r}
trData <- read.csv("pml-training.csv", na.strings=c("NA",""), header=TRUE)
trDataTidy <- filter(trData, new_window == "no")
trDataTidy <- trDataTidy[,-c(1,2,6,7,12:36,50:59,69:83,87:101,103:112,125:139,141:150)]
```

The metadata rows were removed as they appeared to be some type of aggregate of a particular "window". Since the associated columns had NA values for all the rows with"no" in the new_window column, the author decided to not include those rows.

## Train Model
The author decided develop a model using the Random Forest method with specific trainControl settings to get the best performance vs compute time. The first step was to partition the training set into smaller and larger partitions. The smaller partition was used to train the model. The out-of-bag estimate, oob, was selected as the resampling method which greatly decreased compute time. Fifty folds were used for the K-fold cross-validation with 4 separate validations for the resampling scheme. 

```{r}
train <- createDataPartition(y=trDataTidy$classe, p=0.1, list=FALSE) 
trainData <- trDataTidy[train,] 
myModel <- train(trainData$classe ~ ., method="rf", trControl=trainControl(method = "oob", number = 50, repeats = 4), data=trainData,importance = TRUE) 
```

## Model Results
The final model has an accuracy of about 98% as shown in the printout below. Our error rate with the training data is 0.025.
```{r}
print(myModel, digits=3)
```

We then used this model to predict on the larger partition of our training dataset to see how it does. The table below shows our results.
```{r}
trainPartition2 <- trDataTidy[-train,]
pred <- predict(myModel, newdata=trainPartition2)
conMatrix <-confusionMatrix(pred, trainPartition2$classe)
conMatrix
```
So our model predicted about ``r sprintf("%.00f%%", 100 * conMatrix$overall[[1]]) `` of the activity types correctly. Our model as a error rate of ``r  1 - conMatrix$overall[[1]] ``. The model was then used to predict the classe value of the test set and this was submitted to Coursera per the project instructions.